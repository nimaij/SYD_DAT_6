{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification and Regression Trees\n",
    "\n",
    "## Monday November 7, 2016\n",
    "\n",
    "\n",
    "\n",
    "Fill in missing code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read, Explore, and Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "titanic = pd.read_csv('titanic.csv')\n",
    "\n",
    "# Take a  selection of the features\n",
    "d = titanic[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check for missing values in all columns\n",
    "d.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check for missing values in Age column, after grouping by other columns\n",
    "d.groupby(['Sex', 'Pclass']).Age.apply(lambda x: x.isnull().sum()) / d.groupby(['Sex', 'Pclass']).Age.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fill in missing values with the mean value (use .fillna())\n",
    "d['Age'] = d['Age'].fillna(d['Age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert any text categorical features to numeric for scikit learn\n",
    "d['Sex'] = np.where(d.Sex == 'female', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Explore the data to identify trends in characteristics of survivors\n",
    "d.Survived.value_counts()                    # How many people lived and died\n",
    "d.Survived.mean()                            # The survival rate for everyone\n",
    "d.groupby('Sex').Survived.mean()             # By Sex: women have higher survival rates\n",
    "d.groupby('Pclass').Survived.mean()          # By Pclass: 1st class passengers have higher survival rates\n",
    "d.groupby(['Sex', 'Pclass']).Survived.mean() # By Sex and Pclass: Women in the 1st and 2nd classes had the highest survival rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a new feature representing whether the Spouse was on board\n",
    "d['Spouse'] = ((d.Age > 18) & (d.SibSp >= 1)).astype(int)\n",
    "d.Spouse.value_counts()\n",
    "d.groupby(['Pclass', 'Spouse']).Survived.mean() # Having a spouse appears to increase survival in the 1st class only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into training and test datasets, and build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "survived = d['Survived']\n",
    "del d['Survived']\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now, split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(d,survived, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0bc931194b30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create a decision tree classifier object (start out with a small tree for interpretability)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mctree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Fit the decision tree classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtreef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# specifies the whole decision tree, can specify the depth though this default function does it auto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tree' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a decision tree classifier object (start out with a small tree for interpretability)\n",
    "ctree = tree.DecisionTreeClassifier(random_state=1, max_depth=2)\n",
    "\n",
    "# Fit the decision tree classifier\n",
    "treef = ctree.fit(X_train, y_train) # specifies the whole decision tree, can specify the depth though this default function does it auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"d.dot\", 'w') as f:\n",
    "    f = tree.export_graphviz(treef, out_file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualising the decision tree\n",
    "import os\n",
    "os.unlink('d.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pydotplus \n",
    "dot_data = tree.export_graphviz(treef, out_file='tree') \n",
    "graph = pydotplus.graph_from_dot_data(dot_data) \n",
    "graph.write_pdf(\"tree.pdf\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How to interpret the diagram?\n",
    "ctree.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a plotting function that will plot a nice confusion matrix see: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load confusion_matrix_nice.py\n",
    "# from confusion_matrix_nice import plot_confusion_matrix\n",
    "%run confusion_matrix_nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the predictions (not the probabilities)\n",
    "y_pred_class = ctree.predict(X_test)\n",
    "\n",
    "# plot an attractive confusion matrix\n",
    "cnf_mat = metrics.confusion_matrix(y_test, y_pred_class, labels = titanic.Survived.unique())\n",
    "class_labels = titanic.Survived.unique()\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_mat, class_labels,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a feature vector for reference. We will create fictional values for test observations. \n",
    "features = X_train.columns.tolist()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict what will happen for 1st class woman\n",
    "#features\n",
    "ctree.predict_proba([1, 1, 25, 0, 0, 0])\n",
    "ctree.predict([1, 1, 25, 0, 0, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Predict what will happen for a 3rd class man\n",
    "ctree.predict_proba([3, 0, 25, 0, 0, 0])\n",
    "ctree.predict([3, 0, 25, 0, 0, 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Which features are the most important? - sex\n",
    "ctree.feature_importances_\n",
    "\n",
    "# Make a Dataframe out of the features and the importance measure for the features\n",
    "pd.DataFrame(zip(features, ctree.____________)).sort_index(by=1, ascending=False)\n",
    "\n",
    "# Make predictions on the test set\n",
    "preds = ctree.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "metrics.accuracy_score(y_test, preds)\n",
    "\n",
    "# Confusion matrix\n",
    "pd.crosstab(y_test, preds, rownames=['actual'], colnames=['predicted'])\n",
    "\n",
    "# Make predictions on the test set using predict_proba\n",
    "probs = ctree._________(X_test)[:,1]\n",
    "\n",
    "# Calculate the AUC metric\n",
    "metrics.roc_auc_score(y_test, probs)\n",
    "\n",
    "# Decision Trees have notorouisly high variance, so what can we do\n",
    "# to better estimate the out of sample error of a high variance model?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare against Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "ctree = tree.DecisionTreeClassifier(random_state=1, max_depth=2)\n",
    "\n",
    "# compare AUC using cross-validation\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "cross_val_score(logreg, d, survived, cv=10, scoring='roc_auc').mean() #auc:area under the curve\n",
    "cross_val_score(ctree, d, survived, cv=10, scoring='roc_auc').mean()\n",
    "\n",
    "# so far logistic regression is winning..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FINE-TUNING THE TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# check CV score for max depth = 3\n",
    "ctree = tree.DecisionTreeClassifier(max_depth=3)\n",
    "np.mean(cross_val_score(ctree, d, survived, cv=5, scoring='roc_auc'))\n",
    "\n",
    "# check CV score for max depth = 10\n",
    "ctree = tree.DecisionTreeClassifier(max_depth=10)\n",
    "np.mean(cross_val_score(ctree, d, survived, cv=5, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Conduct a grid search for the best tree depth\n",
    "ctree = tree.DecisionTreeClassifier(random_state=1)\n",
    "depth_range = range(1, 20)\n",
    "param_grid = dict(max_depth=depth_range)\n",
    "grid = GridSearchCV(ctree, param_grid, cv=5, scoring='roc_auc')\n",
    "grid.fit(d, survived)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Check out the scores of the grid search\n",
    "grid_mean_scores = [result[1] for result in grid.grid_scores_]\n",
    "\n",
    "\n",
    "# Plot the results of the grid search\n",
    "plt.figure()\n",
    "plt.plot(depth_range, grid_mean_scores)\n",
    "plt.hold(True)\n",
    "plt.grid(True)\n",
    "plt.plot(grid.best_params_['max_depth'], grid.best_score_, 'ro', markersize=12, markeredgewidth=1.5,\n",
    "         markerfacecolor='None', markeredgecolor='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Get the best estimator\n",
    "best = grid.best_estimator_\n",
    "\n",
    "cross_val_score(best, d, survived, cv=10, scoring='roc_auc').mean()\n",
    "cross_val_score(logreg, d, survived, cv=10, scoring='roc_auc').mean()\n",
    "\n",
    "\n",
    "# Still not as good as Logistic Regression.. \n",
    "# Let's try something else\n",
    "\n",
    "\n",
    "\n",
    "### EXERCISE ###\n",
    "''' Use Grid Search try scan over three parameters\n",
    "1. max_depth:     from 1 to 20\n",
    "2. criterion:     (either 'gini' or 'entropy')\n",
    "3. max_features : range (1,5)\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Decision trees (like many other classification models)\n",
    "# can also be used for regression!\n",
    "\n",
    "\n",
    "drinks = pd.read_csv('drinks.csv', na_filter=False)\n",
    "\n",
    "drinks\n",
    "\n",
    "# Make dummy columns for each of the 6 regions\n",
    "for continent_ in ['AS', 'NA', 'EU', 'AF', 'SA', 'OC']:\n",
    "    drinks[continent_] = drinks['continent'] == continent_\n",
    "\n",
    "drinks\n",
    "\n",
    "\n",
    "del drinks['continent']\n",
    "del drinks['country']\n",
    "del drinks['total_litres_of_pure_alcohol'] # this doesn't seem fair does it?\n",
    "\n",
    "X = drinks.drop('wine_servings', axis=1)\n",
    "y = drinks['wine_servings']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)\n",
    "\n",
    "\n",
    "rtree = tree.DecisionTreeRegressor()\n",
    "\n",
    "rtree.fit(X_train, y_train)\n",
    "rtree.predict(X_test)\n",
    "\n",
    "scores = - cross_val_score(rtree, X, y, cv=10, scoring='neg_mean_squared_error')\n",
    "mse_scores = scores\n",
    "mse_scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores\n",
    "rmse_scores.mean()\n",
    "\n",
    "wine_mean = y.mean()\n",
    "wine_mean\n",
    "\n",
    "features = X.columns\n",
    "pd.DataFrame(zip(features, rtree.feature_importances_)).sort_values(by=1, ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
